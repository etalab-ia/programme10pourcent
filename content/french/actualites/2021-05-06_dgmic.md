---
title: "Publication d'une étude sur les méthodologies d'audit des algorithmes de recommandation de contenus"
slug: publication-etude-methodologie-audit-algorithmes-dgmic
date: 2021-05-06T13:00:00+01:00
summary: La Direction Générale des Médias et des Industries Culturelles (DGMIC / Ministère de la Culture), dans le cadre de sa partiticipation à un groupe de travail international multipartite sur la diversité des contenus en ligne, a commandé au PEReN et à Inria/Regalia une étude de faisabilité évaluant les conditions dans lesquelles des audits d'algorithmes de recommandation de contenu seraient possibles.
images:
- /actualites/blackbox-auditing.jpg
---

La [Direction Générale des Médias et des Industries Culturelles](https://www.culture.gouv.fr/Nous-connaitre/Organisation/La-direction-generale-des-medias-et-des-industries-culturelles) (DGMIC / Ministère de la Culture), dans le cadre de sa participation à un [groupe de travail international multipartite sur la diversité des contenus en ligne](https://www.canada.ca/fr/patrimoine-canadien/services/diversite-contenus-ere-numerique.html), a commandé au PEReN et à [Inria/Regalia][1] une étude de faisabilité évaluant les conditions dans lesquelles des audits d'algorithmes de recommandation de contenu seraient possibles.

**Dans cette étude, nous dressons un état des lieux des méthodes d’évaluation des algorithmes de recommandation pouvant être mises en œuvre, selon une double progression de coût à la charge du régulateur et de la plateforme auditée ainsi que de granularité de l'audit**. Il s’agit d’abord de présenter les principes de fonctionnement d'un algorithme de recommandation, compris ici comme un algorithme filtrant des objets issues d'un catalogue (potentiellement extrêmement large) à un utilisateur ou un segment d'utilisateurs donné, sur la base de certaines de leurs propriétés (usage de la plateforme, centres d'intérêt, valeur économique du contenu, etc.), tout en prenant en compte les retours de l'utilisateur (<em lang="en">like</em>, commentaires, temps passé, abandon, etc.).

**Dans un second temps, le rapport s'attache à présenter les méthodes mobilisables par un tiers auditeur en vue de collecter des données représentatives, essentielles à toute analyse statistique d’un algorithme en boîte noire**. Une telle analyse, qualifiée "d’audit en transparence faible", constitue une troisième voie permettant d'envisager une analyse plus fine que ce qui serait permis par l'envoi de questionnaires tout en allégeant les risques (propriété intellectuelle, données personnelles, etc.) d'un audit intégral de code source ou de données (audit en boîte blanche). En particulier, les possibilités d’avoir recours à des audits ponctuels d'échantillons de code source ou de jeux de données, à des remontées volontaires ou rémunérées de la part des utilisateurs, ou encore à de la collecte directe d'informations depuis les interfaces publiques de la plateforme afin de constituer un jeu de données plus conséquent sont analysées selon cette double progression de coût/granularité de l'audit.

**Enfin, l'étude étudie les analyses possibles de telles données, afin de mener à terme des audits d’algorithmes de recommandation, selon trois scénarios type d'intérêt pour un régulateur** :

* **Des mesures d’exposition croisées selon une double segmentation des utilisateurs et des contenus** (la segmentation des utilisateurs et des contenus étant connue à l'avance) , il pourrait alors s'agir de vérifier qu'un algorithme de modération ne recommande pas davantage de contenus violent à des utilisateurs identifiés comme étant de sexe masculin qu'à des utilisateurs identifiés comme étant de sexe féminin ;
* **L’identification de biais potentiels au sein d’un algorithme de recommandation** (c'est-à-dire de déterminer une segmentation de contenus ou d'utilisateurs), il pourrait alors s'agir de déterminer quelles catégories de contenu bénéficient le plus des recommandations algorithmiques ;
* **La compréhension plus fine d’un mécanisme algorithmique, par la réalisation d’un modèle simplifié (virtuel) de l’algorithme**, il pourrait alors s'agir de déterminer quelles sont les principaux paramètres expliquant les recommandations d'un algorithme donné.


Le PEReN et Inria/Regalia ont pu présenter ces travaux et les enseignements de cette étude devant le groupe de travail multipartite sur la diversité des contenus en ligne piloté par le ministère du Patrimoine canadien, le 28 mai dernier. Cette étude, qui dresse les premières bases théoriques des méthodes d'audit d'algorithmes en boîte noire co-développées par [le PEReN et Inria/Regalia](https://www.inria.fr/fr/regulation-plateformes-numeriques-peren-regalia) ouvre désormais la voie à la réalisation de validations et de démonstrations expérimentales de ces méthodes d'audit en boîte noire sur des algorithmes spécifiquement identifiés.


**L'étude complète est téléchargeable en {{% link "rapports/2021-05-06 - Méthodes d'audit des algorithmes de recommandation - PEReN-Regalia.pdf" %}}version française{{% /link %}}. {{% link "rapports/2021-05-06 - Evaluation Methods for Content Recommendation Algorithms - PEReN-Regalia.pdf" %}}Une traduction en langue anglaise{{% /link %}} est également disponible.** Ce fichier peut ne pas être adapté à des utilisateurs de technologies d'assistance, vous pouvez nous en [demander une version accessible](https://www.peren.gouv.fr/contact/) dans ce cas.


[1]: https://www.inria.fr/fr
